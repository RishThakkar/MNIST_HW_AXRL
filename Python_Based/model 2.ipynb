{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae9f783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from skimage.transform import resize\n",
    "import h5py\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c655504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Resize images to 42x42\n",
    "x_train_resized = np.zeros((x_train.shape[0], 42, 42))\n",
    "for i in range(x_train.shape[0]):\n",
    "    x_train_resized[i] = resize(x_train[i], (42, 42))\n",
    "\n",
    "x_test_resized = np.zeros((x_test.shape[0], 42, 42))\n",
    "for i in range(x_test.shape[0]):\n",
    "    x_test_resized[i] = resize(x_test[i], (42, 42))\n",
    "\n",
    "# Reshape to add channel dimension (required for Keras)\n",
    "x_train_resized = x_train_resized.reshape(-1, 42, 42, 1)\n",
    "x_test_resized = x_test_resized.reshape(-1, 42, 42, 1)\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "x_train_resized = x_train_resized.astype('float32') / 255.0\n",
    "x_test_resized = x_test_resized.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22512bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape=(42, 42, 1)))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(4, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model (Replace X_train and y_train with your training data)\n",
    "# model.fit(x_train_resized, y_train, batch_size=50, epochs=15, validation_data=(x_test_resized, y_test))\n",
    "\n",
    "# # Save the model's weights and biases\n",
    "# model.save('model_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e82956f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# # Load the model from the .h5 file\n",
    "# model = load_model('model_weights.h5')\n",
    "\n",
    "# # Get the weights for each layer\n",
    "# weights = model.get_weights()\n",
    "\n",
    "# # Save the weights to a text file\n",
    "# with open('model_weights.txt', 'w') as file:\n",
    "#     for layer_weights in weights:\n",
    "#         for weight in layer_weights.flatten():\n",
    "#             file.write(str(weight) + '\\n')\n",
    "\n",
    "# print(\"Model weights saved to model_weights.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aced222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee72011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 0.9181 - loss: 0.2984\n",
      "Test Loss: 0.2572062909603119\n",
      "Test Accuracy: 0.9316999912261963\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model = load_model('model_weights.h5')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(x_test_resized, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b90702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Predicted class probabilities: [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "Predicted class label: 3\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the single image\n",
    "img_path = 'demo7.png'  \n",
    "img = image.load_img(img_path, target_size=(42, 42), color_mode='grayscale')  \n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "# img_array /= 255.  # Normalize the pixel values\n",
    "\n",
    "# Predict the output of the model for the single image\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Print the predicted class probabilities\n",
    "print(\"Predicted class probabilities:\", predictions)\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_class = np.argmax(predictions)\n",
    "print(\"Predicted class label:\", predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ee045",
   "metadata": {},
   "source": [
    "# Conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca4f15c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Output shape of the first convolutional layer: (1, 40, 40, 4)\n",
      "Convolutional layer output saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rishit Thakkar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "weights_and_biases = np.loadtxt(\"model_weights.txt\")\n",
    "\n",
    "weights_shape = (3, 3, 1, 4)  # Assuming kernel size of (3, 3) and 4 filters\n",
    "\n",
    "weights = weights_and_biases[0:36].reshape(weights_shape)  # weights\n",
    "biases = weights_and_biases[36:40]  # biases\n",
    "\n",
    "\n",
    "#Model Below\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape=(42, 42, 1)))\n",
    "\n",
    "model.layers[0].set_weights([weights, biases])\n",
    "\n",
    "\n",
    "\n",
    "img_path = 'demo7.png'  \n",
    "img = image.load_img(img_path, target_size=(42, 42), color_mode='grayscale')  \n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "# img_array /= 255.  \n",
    "img_flat = img_array.flatten()\n",
    "img_array = np.array(img_flat)\n",
    "\n",
    "\n",
    "img_array = img_flat.reshape((1, 42, 42, 1))  # Reshape to (batch_size, height, width, channels)\n",
    "\n",
    "conv1_output = model.predict(img_array)\n",
    "\n",
    "print(\"Output shape of the first convolutional layer:\", conv1_output.shape)\n",
    "\n",
    "# Save the convolutional layer output\n",
    "with open('Python_prog_out_conv.txt', 'w') as file:\n",
    "    for c in range(conv1_output.shape[3]):  \n",
    "        file.write(\"Channel %d:\\n\" % (c + 1))\n",
    "\n",
    "        for i in range(conv1_output.shape[1]):  \n",
    "            for j in range(conv1_output.shape[2]):  \n",
    "                file.write(\"%0.2f\" % conv1_output[0, i, j, c])\n",
    "                if j != conv1_output.shape[2] - 1:\n",
    "                    file.write(\", \")\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "print(\"Convolutional layer output saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d907c86f",
   "metadata": {},
   "source": [
    "# Max1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76ec5767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Output shape of the first Max Pool layer: (1, 20, 20, 4)\n",
      "Max 1 layer output saved\n"
     ]
    }
   ],
   "source": [
    "weights_and_biases = np.loadtxt(\"model_weights.txt\")\n",
    "\n",
    "weights_shape = (3, 3, 1, 4)  # Assuming kernel size of (3, 3) and 4 filters\n",
    "\n",
    "weights = weights_and_biases[0:36].reshape(weights_shape)  # weights\n",
    "biases = weights_and_biases[36:40]  # biases\n",
    "\n",
    "\n",
    "#Model Below\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape=(42, 42, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.layers[0].set_weights([weights, biases])\n",
    "\n",
    "\n",
    "\n",
    "img_path = 'demo7.png'  \n",
    "img = image.load_img(img_path, target_size=(42, 42), color_mode='grayscale')  \n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "# img_array /= 255.  \n",
    "img_flat = img_array.flatten()\n",
    "img_array = np.array(img_flat)\n",
    "\n",
    "\n",
    "img_array = img_flat.reshape((1, 42, 42, 1))  # Reshape to (batch_size, height, width, channels)\n",
    "\n",
    "conv1_output = model.predict(img_array)\n",
    "\n",
    "print(\"Output shape of the first Max Pool layer:\", conv1_output.shape)\n",
    "\n",
    "# Save the convolutional layer output\n",
    "with open('Python_prog_out_Max1.txt', 'w') as file:\n",
    "    for c in range(conv1_output.shape[3]):  \n",
    "        file.write(\"Channel %d:\\n\" % (c + 1))\n",
    "\n",
    "        for i in range(conv1_output.shape[1]):  \n",
    "            for j in range(conv1_output.shape[2]):  \n",
    "                file.write(\"%0.2f\" % conv1_output[0, i, j, c])\n",
    "                if j != conv1_output.shape[2] - 1:\n",
    "                    file.write(\", \")\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "print(\"Max 1 layer output saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdefbaf1",
   "metadata": {},
   "source": [
    "# Conv 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fde0b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Output shape of the first convolutional layer: (1, 18, 18, 4)\n",
      "Convolutional layer output saved\n"
     ]
    }
   ],
   "source": [
    "weights_and_biases = np.loadtxt(\"model_weights.txt\")\n",
    "\n",
    "weights_shape = (3, 3, 1, 4)  # Assuming kernel size of (3, 3) and 4 filters\n",
    "weights2_shape = (3, 3, 4, 4)\n",
    "\n",
    "weights = weights_and_biases[0:36].reshape(weights_shape)  # weights\n",
    "biases = weights_and_biases[36:40]  # biases\n",
    "\n",
    "weights2 = weights_and_biases[40:184].reshape(weights2_shape)\n",
    "biases2 = weights_and_biases[184:188]\n",
    "\n",
    "#Model Below\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape=(42, 42, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.layers[0].set_weights([weights, biases])\n",
    "model.layers[2].set_weights([weights2, biases2])\n",
    "\n",
    "\n",
    "\n",
    "img_path = 'demo7.png'  \n",
    "img = image.load_img(img_path, target_size=(42, 42), color_mode='grayscale')  \n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "# img_array /= 255.  \n",
    "img_flat = img_array.flatten()\n",
    "img_array = np.array(img_flat)\n",
    "\n",
    "\n",
    "img_array = img_flat.reshape((1, 42, 42, 1))  # Reshape to (batch_size, height, width, channels)\n",
    "\n",
    "conv1_output = model.predict(img_array)\n",
    "\n",
    "print(\"Output shape of the first convolutional layer:\", conv1_output.shape)\n",
    "\n",
    "# Save the convolutional layer output\n",
    "with open('Python_prog_out_conv2.txt', 'w') as file:\n",
    "    for c in range(conv1_output.shape[3]):  \n",
    "        file.write(\"Channel %d:\\n\" % (c + 1))\n",
    "\n",
    "        for i in range(conv1_output.shape[1]):  \n",
    "            for j in range(conv1_output.shape[2]):  \n",
    "                file.write(\"%0.2f\" % conv1_output[0, i, j, c])\n",
    "                if j != conv1_output.shape[2] - 1:\n",
    "                    file.write(\", \")\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "print(\"Convolutional layer output saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acb6353",
   "metadata": {},
   "source": [
    "# Max 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9931121e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001E782C29BC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001E782C29BC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Output shape of the 2nd MaxPool layer: (1, 9, 9, 4)\n",
      "Maxpool layer 2 output saved\n"
     ]
    }
   ],
   "source": [
    "weights_and_biases = np.loadtxt(\"model_weights.txt\")\n",
    "\n",
    "weights_shape = (3, 3, 1, 4)  # Assuming kernel size of (3, 3) and 4 filters\n",
    "weights2_shape = (3, 3, 4, 4)\n",
    "\n",
    "weights = weights_and_biases[0:36].reshape(weights_shape)  # weights\n",
    "biases = weights_and_biases[36:40]  # biases\n",
    "\n",
    "weights2 = weights_and_biases[40:184].reshape(weights2_shape)\n",
    "biases2 = weights_and_biases[184:188]\n",
    "\n",
    "#Model Below\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape=(42, 42, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.layers[0].set_weights([weights, biases])\n",
    "model.layers[2].set_weights([weights2, biases2])\n",
    "\n",
    "\n",
    "\n",
    "img_path = 'demo7.png'  \n",
    "img = image.load_img(img_path, target_size=(42, 42), color_mode='grayscale')  \n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "# img_array /= 255.  \n",
    "img_flat = img_array.flatten()\n",
    "img_array = np.array(img_flat)\n",
    "\n",
    "\n",
    "img_array = img_flat.reshape((1, 42, 42, 1))  # Reshape to (batch_size, height, width, channels)\n",
    "\n",
    "conv1_output = model.predict(img_array)\n",
    "\n",
    "print(\"Output shape of the 2nd MaxPool layer:\", conv1_output.shape)\n",
    "\n",
    "# Save the convolutional layer output\n",
    "with open('Python_prog_out_max2.txt', 'w') as file:\n",
    "    for c in range(conv1_output.shape[3]):  \n",
    "        file.write(\"Channel %d:\\n\" % (c + 1))\n",
    "\n",
    "        for i in range(conv1_output.shape[1]):  \n",
    "            for j in range(conv1_output.shape[2]):  \n",
    "                file.write(\"%0.2f\" % conv1_output[0, i, j, c])\n",
    "                if j != conv1_output.shape[2] - 1:\n",
    "                    file.write(\", \")\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "print(\"Maxpool layer 2 output saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980f6bb2",
   "metadata": {},
   "source": [
    "# Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc77e080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-2.64759470e+00  9.48329200e-01  7.22843000e-01 -1.82670260e+00]\n",
      "   [ 6.09292540e-02 -1.44774630e-01 -2.15200110e-01  1.98423040e-02]\n",
      "   [ 2.03331220e-01  4.21472300e-02  4.69026800e-02  2.53995200e-01]\n",
      "   [-2.58511730e+00  6.44776460e-01  3.96601800e-01 -2.26895020e+00]]\n",
      "\n",
      "  [[-3.45524290e+00  5.41710400e-01  2.00895790e+00 -7.16897100e-01]\n",
      "   [ 1.54876710e-01 -2.45558540e-01 -8.68982500e-02  2.87901700e-02]\n",
      "   [ 5.68736200e-02  1.44750570e-01 -2.13798760e-01  2.59440100e-01]\n",
      "   [-3.34199260e+00  8.65652600e-01  2.02273600e+00 -9.24704600e-01]]\n",
      "\n",
      "  [[-3.55474800e+00 -1.16067660e+00  4.85305250e-01  2.68154050e-01]\n",
      "   [-1.43806470e-01 -1.55931560e-01  2.00733060e-02 -1.84719740e-01]\n",
      "   [ 1.84435000e-01 -2.25904830e-02 -2.39373030e-01  1.54186190e-01]\n",
      "   [-3.78928350e+00 -8.91361830e-01  9.41256170e-01 -1.42298770e-01]]]\n",
      "\n",
      "\n",
      " [[[ 7.29974200e-01  9.42887500e-01  1.03263510e+00  3.61674820e-01]\n",
      "   [-1.54911230e-02  1.23387866e-01 -3.20493130e-02  2.20656650e-01]\n",
      "   [ 2.28943270e-01  2.05836100e-01 -3.48753330e-02  2.23499000e-01]\n",
      "   [ 8.84783400e-01  1.28679100e+00  9.10770100e-01  8.49061500e-01]]\n",
      "\n",
      "  [[ 7.45399600e-01  1.47567610e+00  2.09761430e+00  1.50286800e+00]\n",
      "   [ 1.78141040e-01  1.34556260e-03  4.73379230e-02  1.10443630e-01]\n",
      "   [ 2.87005960e-01 -1.79954630e-01  2.72246030e-01 -1.34293720e-01]\n",
      "   [ 2.80836940e-01  1.32274930e+00  2.20111300e+00  1.23044880e+00]]\n",
      "\n",
      "  [[ 2.58240940e-01 -3.18569170e-02  9.62754550e-01  1.35986650e+00]\n",
      "   [ 8.89778400e-02 -1.30320010e-01  3.33690530e-02  8.36582100e-02]\n",
      "   [ 2.85493280e-01  8.41570940e-02 -1.34487590e-02 -2.13845330e-01]\n",
      "   [ 2.94216000e-01  1.43338490e-01  1.44651820e+00  1.53524470e+00]]]\n",
      "\n",
      "\n",
      " [[[ 2.40875460e+00  1.07874300e+00  2.16787400e-01  1.08137430e+00]\n",
      "   [ 2.25766350e-01  2.03830190e-02  5.00691270e-02  2.43743960e-01]\n",
      "   [ 2.81187270e-01  4.39097170e-02  1.14240214e-01 -9.76284400e-02]\n",
      "   [ 2.42790250e+00  1.14857090e+00 -1.19375800e-01  1.18284450e+00]]\n",
      "\n",
      "  [[ 1.61999180e+00  8.64293900e-01  9.93966040e-01  7.46510860e-01]\n",
      "   [ 2.31252860e-01  2.78854850e-01  1.48426060e-01 -2.25946140e-01]\n",
      "   [ 1.56506870e-01  2.92558160e-01  1.76726670e-01 -1.23071970e-01]\n",
      "   [ 1.98363570e+00  1.45877780e+00  1.22868660e+00  9.57044960e-01]]\n",
      "\n",
      "  [[ 1.58414140e+00  9.12636800e-01  8.99002430e-01  1.01622530e+00]\n",
      "   [ 1.40231040e-01 -5.89799400e-02 -1.95011270e-01  4.86628820e-02]\n",
      "   [ 1.40378160e-01 -6.84343400e-04 -9.66553100e-02 -1.80941200e-01]\n",
      "   [ 1.62005350e+00  1.27934520e+00  6.78401000e-01  1.26499830e+00]]]]\n",
      "(3, 3, 4, 4)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Output shape of the Flatten layer: (1, 324)\n",
      "Flatten layer output saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rishit Thakkar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "weights_and_biases = np.loadtxt(\"model_weights.txt\")\n",
    "\n",
    "weights_shape = (3, 3, 1, 4)  # Assuming kernel size of (3, 3) and 4 filters\n",
    "weights2_shape = (3, 3, 4, 4)\n",
    "weights3_shape = (324, 10)\n",
    "\n",
    "weights = weights_and_biases[0:36].reshape(weights_shape)  # weights\n",
    "biases = weights_and_biases[36:40]  # biases\n",
    "\n",
    "weights2 = weights_and_biases[40:184].reshape(weights2_shape)\n",
    "biases2 = weights_and_biases[184:188]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Model Below\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape=(42, 42, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.layers[0].set_weights([weights, biases])\n",
    "model.layers[2].set_weights([weights2, biases2])\n",
    "\n",
    "\n",
    "img_path = 'demo7.png'  \n",
    "img = image.load_img(img_path, target_size=(42, 42), color_mode='grayscale')  \n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "# img_array /= 255.  \n",
    "img_flat = img_array.flatten()\n",
    "img_array = np.array(img_flat)\n",
    "\n",
    "\n",
    "img_array = img_flat.reshape((1, 42, 42, 1))  # Reshape to (batch_size, height, width, channels)\n",
    "\n",
    "conv1_output = model.predict(img_array)\n",
    "\n",
    "# Save the convolutional layer output\n",
    "print(\"Output shape of the Flatten layer:\", conv1_output.shape)\n",
    "\n",
    "# Save the flatten layer output\n",
    "with open('Python_prog_out_Flatten.txt', 'w') as file:\n",
    "    for i in range(conv1_output.shape[1]):\n",
    "        file.write(\"Neuron %d: %0.2f\\n\" % (i + 1, conv1_output[0, i]))\n",
    "\n",
    "print(\"Flatten layer output saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59abb0ad",
   "metadata": {},
   "source": [
    "# Flatten and Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2f8aaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0628828   0.08443162 -0.06693464 ... -0.16860108 -0.2712759\n",
      "  -0.5382995 ]\n",
      " [-0.56143224  0.04709087 -0.01200746 ... -0.04370009 -0.51703787\n",
      "   0.00160865]\n",
      " [-0.05777652  0.05571867 -0.13674326 ... -0.02451991 -0.29477504\n",
      "   0.09512035]\n",
      " ...\n",
      " [-0.6929802  -0.3816776  -0.16954614 ... -0.54828227 -0.22178961\n",
      "   0.8018081 ]\n",
      " [-0.4157763  -0.32710147 -0.19066389 ... -0.6222933  -0.4254632\n",
      "   0.67794114]\n",
      " [-0.6351339  -0.35842043  0.05096419 ... -0.6506854  -0.4093783\n",
      "   0.61668533]]\n",
      "(324, 10)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Output shape of the Dense layer: (1, 10)\n",
      "Dense layer output saved\n"
     ]
    }
   ],
   "source": [
    "weights_and_biases = np.loadtxt(\"model_weights.txt\")\n",
    "\n",
    "weights_shape = (3, 3, 1, 4)  # Assuming kernel size of (3, 3) and 4 filters\n",
    "weights2_shape = (3, 3, 4, 4)\n",
    "weights3_shape = (324, 10)\n",
    "\n",
    "weights = weights_and_biases[0:36].reshape(weights_shape)  # weights\n",
    "biases = weights_and_biases[36:40]  # biases\n",
    "\n",
    "weights2 = weights_and_biases[40:184].reshape(weights2_shape)\n",
    "biases2 = weights_and_biases[184:188]\n",
    "\n",
    "weights3 = weights_and_biases[188:3428].reshape(weights3_shape)\n",
    "biases3 = weights_and_biases[3428:3438]\n",
    "\n",
    "print(weights3)\n",
    "print(weights3.shape)\n",
    "\n",
    "#Model Below\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape=(42, 42, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "model.layers[0].set_weights([weights, biases])\n",
    "model.layers[2].set_weights([weights2, biases2])\n",
    "model.layers[5].set_weights([weights3, biases3])\n",
    "\n",
    "\n",
    "img_path = 'demo7.png'  \n",
    "img = image.load_img(img_path, target_size=(42, 42), color_mode='grayscale')  \n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "# img_array /= 255.  \n",
    "img_flat = img_array.flatten()\n",
    "img_array = np.array(img_flat)\n",
    "\n",
    "\n",
    "img_array = img_flat.reshape((1, 42, 42, 1))  # Reshape to (batch_size, height, width, channels)\n",
    "\n",
    "conv1_output = model.predict(img_array)\n",
    "\n",
    "# Save the convolutional layer output\n",
    "print(\"Output shape of the Dense layer:\", conv1_output.shape)\n",
    "\n",
    "# Save the dense layer output\n",
    "with open('Python_prog_out_Dense.txt', 'w') as file:\n",
    "    for i in range(conv1_output.shape[1]):\n",
    "        file.write(\"Neuron %d: %0.2f\\n\" % (i + 1, conv1_output[0, i]))\n",
    "\n",
    "print(\"Dense layer output saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb21054c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0628828   0.08443162 -0.06693464 ... -0.16860108 -0.2712759\n",
      "  -0.5382995 ]\n",
      " [-0.56143224  0.04709087 -0.01200746 ... -0.04370009 -0.51703787\n",
      "   0.00160865]\n",
      " [-0.05777652  0.05571867 -0.13674326 ... -0.02451991 -0.29477504\n",
      "   0.09512035]\n",
      " ...\n",
      " [-0.6929802  -0.3816776  -0.16954614 ... -0.54828227 -0.22178961\n",
      "   0.8018081 ]\n",
      " [-0.4157763  -0.32710147 -0.19066389 ... -0.6222933  -0.4254632\n",
      "   0.67794114]\n",
      " [-0.6351339  -0.35842043  0.05096419 ... -0.6506854  -0.4093783\n",
      "   0.61668533]]\n",
      "(324, 10)\n",
      "[-6.69346400e-02 -1.20074630e-02 -1.36743260e-01 -1.06903460e-01\n",
      "  3.94939800e-02  3.18853320e-01  1.57462330e-01  2.42653010e-01\n",
      "  1.74437630e-01  5.01645500e-01  6.02862700e-01  4.03753820e-01\n",
      "  7.97290800e-02  5.61858950e-01  6.43399500e-01  3.93291320e-01\n",
      "  1.04357320e-01  4.62855850e-01  6.82405650e-01  3.19821600e-01\n",
      "  8.16873240e-02  4.47457100e-01  5.41214470e-01  2.68627800e-01\n",
      " -7.71088300e-02  2.17887300e-01  2.86196170e-01  1.56687300e-02\n",
      " -2.58964900e-01 -2.19503800e-01 -2.26970900e-01 -2.79147620e-01\n",
      " -4.83478930e-01 -8.54266500e-01 -7.23990440e-01 -9.43319900e-01\n",
      "  1.15210460e-01  2.18503180e-01  7.07100850e-02  1.21528305e-01\n",
      "  1.76364750e-01  2.33369230e-01  8.69425460e-02  2.14612130e-01\n",
      "  2.00271380e-01  2.17901810e-01  9.55107400e-02  1.36218320e-01\n",
      "  7.05552550e-02  2.04590480e-01  9.60609000e-02  6.09625130e-02\n",
      "  5.01380150e-02  1.01663776e-01  6.68575840e-02 -8.01666100e-03\n",
      "  3.79756000e-03  7.97018600e-02  5.73645350e-02 -8.08715200e-02\n",
      " -1.65175630e-02 -5.80882600e-03  9.55928500e-02 -1.86786980e-01\n",
      " -1.60731180e-01 -4.05647400e-02  8.28639100e-02 -2.26434770e-01\n",
      " -3.31186740e-01 -5.89431350e-01 -7.08922860e-01 -7.58078340e-01\n",
      "  2.28635890e-01  3.10265300e-01  2.15635460e-01  4.25489520e-01\n",
      "  4.35605300e-01  3.51586450e-02  1.33548435e-02  1.10134730e-02\n",
      "  3.59306500e-01 -3.17575220e-03  4.82592320e-02 -8.75074000e-03\n",
      "  9.91437400e-02 -7.83417800e-02 -5.35398420e-02 -2.03565250e-01\n",
      " -3.24660200e-02 -1.14834554e-01  3.90053170e-02 -1.68139950e-01\n",
      " -4.59771270e-02  1.30065270e-02  5.04514440e-03 -1.09846130e-01\n",
      " -1.46756500e-01  6.93896300e-02  2.91161240e-02 -1.17462810e-01\n",
      " -2.45738060e-01  8.43211900e-03 -2.83922370e-02 -2.41724010e-01\n",
      " -4.80592730e-01 -2.39778040e-01 -5.42171600e-01 -6.99385900e-01\n",
      "  1.59064200e-01 -5.70278940e-01 -3.18428870e-01 -8.84485600e-01\n",
      "  5.75009900e-01 -8.18375200e-01 -5.84667560e-01 -6.34234550e-01\n",
      "  3.02991570e-01 -7.43674930e-01 -4.97726400e-01 -6.15367300e-01\n",
      " -5.14919350e-02 -7.26632950e-01 -5.03124060e-01 -5.97341300e-01\n",
      " -1.39180900e-01 -5.24006370e-01 -3.34138930e-01 -2.25670710e-01\n",
      " -5.52210000e-01 -1.96516840e-01 -8.72566700e-02 -1.12155266e-01\n",
      " -7.49473000e-01  4.86717200e-04  4.32049520e-02 -8.85621300e-02\n",
      " -5.49440860e-01  6.11934400e-02  6.18182120e-02 -2.10554080e-02\n",
      " -1.60669200e-01 -2.54374300e-01 -5.16734840e-01 -1.72774700e-01\n",
      "  5.49594460e-01 -4.21967360e-01 -7.87068400e-01 -4.62257030e-01\n",
      "  1.00786170e+00 -5.42286600e-01 -7.27206100e-01 -2.24203260e-01\n",
      "  6.65519000e-01 -3.91068760e-01 -5.02328460e-01 -2.27968190e-02\n",
      "  6.10850160e-01 -2.18507560e-01 -3.16413400e-01  8.86753100e-02\n",
      "  4.55720600e-01 -7.99952500e-03 -1.02197220e-01  1.85127630e-01\n",
      "  1.01797090e-01 -7.55311800e-02 -1.08809880e-01  6.78144840e-02\n",
      " -3.27377170e-01 -8.92748160e-02 -1.20502190e-02  6.35511950e-02\n",
      " -1.52623220e-01 -5.08861200e-02 -5.74821100e-02 -1.58392650e-01\n",
      "  3.76542660e-01  3.45092000e-02  5.47404740e-02  4.66225330e-01\n",
      "  1.74062420e-01  4.89670370e-01  5.09727000e-01  3.70980470e-01\n",
      "  2.24487980e-01  7.27568330e-03  1.69399440e-02  1.09295010e-01\n",
      "  1.59287440e-01  2.65617280e-02 -5.60852100e-02  1.14306280e-01\n",
      "  2.70381920e-02  9.54255800e-02  1.70555600e-01  2.50500740e-01\n",
      "  1.54621560e-01  2.68506200e-01  1.65988160e-01  2.85437850e-01\n",
      "  1.71458890e-01 -3.30073100e-02  9.68141300e-03  1.05570324e-01\n",
      "  2.33451960e-01 -1.77507720e-02  9.95087100e-02  7.92720500e-02\n",
      "  4.93623300e-01 -4.40954120e-02 -7.11684300e-02  1.99471380e-01\n",
      "  9.47910850e-01  3.18289580e-01  4.39132720e-01  1.10817920e+00\n",
      " -2.00924900e-01  7.15919400e-01  5.45373860e-01  5.56715500e-01\n",
      "  9.57247700e-02  2.87204530e-01  2.84060450e-01  3.39440460e-01\n",
      "  6.28118960e-02  2.24019600e-01  2.36378860e-01  2.63359460e-01\n",
      " -1.20541370e-01  1.57085850e-01  2.00764020e-01  1.12939780e-01\n",
      " -8.01455500e-02  1.16450265e-01  8.54901700e-02 -1.03036460e-01\n",
      "  2.94197740e-01  2.98600230e-02  3.00291760e-02  3.92125360e-02\n",
      "  8.05275400e-01  8.73010100e-02  5.85414700e-02  2.12957130e-01\n",
      "  1.32681400e+00  1.48923080e-01 -2.47282570e-02  3.66956530e-01\n",
      "  1.32353250e+00  2.55557800e-01  3.26835200e-01  8.52741200e-01\n",
      " -3.15008940e-01  6.38463900e-01  6.04217770e-01  5.02760300e-01\n",
      " -3.47600100e-01  3.35034130e-01  3.51426150e-01  3.87518260e-01\n",
      " -2.13958800e-01  1.80393070e-01  2.67914060e-01  2.75912500e-01\n",
      " -3.67882550e-01  7.75847660e-02  8.78598200e-02 -6.89137800e-02\n",
      " -4.96209560e-02 -1.14226230e-01 -9.32215450e-02 -2.71124150e-01\n",
      "  1.46470670e-01 -1.44040520e-01 -9.38055500e-02 -1.79444610e-01\n",
      "  9.07967030e-01  4.58149900e-02 -1.34548600e-02  1.40400250e-01\n",
      "  1.44261750e+00 -1.31226880e-01 -1.89852090e-01  1.66342680e-01\n",
      "  8.00445400e-01  1.35396710e-02  1.02705054e-01  7.08871900e-01\n",
      " -6.77829440e-01 -3.97279380e-01 -4.27062660e-02 -3.63357700e-01\n",
      " -9.81528640e-01 -3.70964800e-01  4.91225900e-02 -5.49853600e-01\n",
      " -1.14582000e+00 -2.86227940e-01  5.60082700e-02 -5.15618440e-01\n",
      " -9.21306900e-01 -2.81312640e-01 -1.16786600e-01 -5.82233000e-01\n",
      " -3.71121970e-01 -4.32709840e-01 -1.78235700e-01 -6.00247560e-01\n",
      " -5.75833000e-03 -4.22335620e-01 -2.04681520e-01 -3.89472200e-01\n",
      "  4.16664540e-01 -3.06492060e-01 -2.52728280e-01 -1.94150570e-01\n",
      "  2.83551600e-01 -3.38423100e-01 -2.82958420e-01 -8.62420200e-02\n",
      "  1.89743010e-01 -1.69546140e-01 -1.90663890e-01  5.09641900e-02]\n",
      "[-3.17575220e-03  4.82592320e-02 -8.75074000e-03  9.91437400e-02\n",
      " -7.83417800e-02 -5.35398420e-02 -2.03565250e-01 -3.24660200e-02\n",
      " -1.14834554e-01  3.90053170e-02 -1.68139950e-01 -4.59771270e-02\n",
      "  1.30065270e-02  5.04514440e-03 -1.09846130e-01 -1.46756500e-01\n",
      "  6.93896300e-02  2.91161240e-02 -1.17462810e-01 -2.45738060e-01\n",
      "  8.43211900e-03 -2.83922370e-02 -2.41724010e-01 -4.80592730e-01\n",
      " -2.39778040e-01 -5.42171600e-01 -6.99385900e-01  1.59064200e-01\n",
      " -5.70278940e-01 -3.18428870e-01 -8.84485600e-01  5.75009900e-01\n",
      " -8.18375200e-01 -5.84667560e-01 -6.34234550e-01  3.02991570e-01\n",
      " -7.43674930e-01 -4.97726400e-01 -6.15367300e-01 -5.14919350e-02\n",
      " -7.26632950e-01 -5.03124060e-01 -5.97341300e-01 -1.39180900e-01\n",
      " -5.24006370e-01 -3.34138930e-01 -2.25670710e-01 -5.52210000e-01\n",
      " -1.96516840e-01 -8.72566700e-02 -1.12155266e-01 -7.49473000e-01\n",
      "  4.86717200e-04  4.32049520e-02 -8.85621300e-02 -5.49440860e-01\n",
      "  6.11934400e-02  6.18182120e-02 -2.10554080e-02 -1.60669200e-01\n",
      " -2.54374300e-01 -5.16734840e-01 -1.72774700e-01  5.49594460e-01\n",
      " -4.21967360e-01 -7.87068400e-01 -4.62257030e-01  1.00786170e+00\n",
      " -5.42286600e-01 -7.27206100e-01 -2.24203260e-01  6.65519000e-01\n",
      " -3.91068760e-01 -5.02328460e-01 -2.27968190e-02  6.10850160e-01\n",
      " -2.18507560e-01 -3.16413400e-01  8.86753100e-02  4.55720600e-01\n",
      " -7.99952500e-03 -1.02197220e-01  1.85127630e-01  1.01797090e-01\n",
      " -7.55311800e-02 -1.08809880e-01  6.78144840e-02 -3.27377170e-01\n",
      " -8.92748160e-02 -1.20502190e-02  6.35511950e-02 -1.52623220e-01\n",
      " -5.08861200e-02 -5.74821100e-02 -1.58392650e-01  3.76542660e-01\n",
      "  3.45092000e-02  5.47404740e-02  4.66225330e-01  1.74062420e-01\n",
      "  4.89670370e-01  5.09727000e-01  3.70980470e-01  2.24487980e-01\n",
      "  7.27568330e-03  1.69399440e-02  1.09295010e-01  1.59287440e-01\n",
      "  2.65617280e-02 -5.60852100e-02  1.14306280e-01  2.70381920e-02\n",
      "  9.54255800e-02  1.70555600e-01  2.50500740e-01  1.54621560e-01\n",
      "  2.68506200e-01  1.65988160e-01  2.85437850e-01  1.71458890e-01\n",
      " -3.30073100e-02  9.68141300e-03  1.05570324e-01  2.33451960e-01\n",
      " -1.77507720e-02  9.95087100e-02  7.92720500e-02  4.93623300e-01\n",
      " -4.40954120e-02 -7.11684300e-02  1.99471380e-01  9.47910850e-01\n",
      "  3.18289580e-01  4.39132720e-01  1.10817920e+00 -2.00924900e-01\n",
      "  7.15919400e-01  5.45373860e-01  5.56715500e-01  9.57247700e-02\n",
      "  2.87204530e-01  2.84060450e-01  3.39440460e-01  6.28118960e-02\n",
      "  2.24019600e-01  2.36378860e-01  2.63359460e-01 -1.20541370e-01\n",
      "  1.57085850e-01  2.00764020e-01  1.12939780e-01 -8.01455500e-02\n",
      "  1.16450265e-01  8.54901700e-02 -1.03036460e-01  2.94197740e-01\n",
      "  2.98600230e-02  3.00291760e-02  3.92125360e-02  8.05275400e-01\n",
      "  8.73010100e-02  5.85414700e-02  2.12957130e-01  1.32681400e+00\n",
      "  1.48923080e-01 -2.47282570e-02  3.66956530e-01  1.32353250e+00\n",
      "  2.55557800e-01  3.26835200e-01  8.52741200e-01 -3.15008940e-01\n",
      "  6.38463900e-01  6.04217770e-01  5.02760300e-01 -3.47600100e-01\n",
      "  3.35034130e-01  3.51426150e-01  3.87518260e-01 -2.13958800e-01\n",
      "  1.80393070e-01  2.67914060e-01  2.75912500e-01 -3.67882550e-01\n",
      "  7.75847660e-02  8.78598200e-02 -6.89137800e-02 -4.96209560e-02\n",
      " -1.14226230e-01 -9.32215450e-02 -2.71124150e-01  1.46470670e-01\n",
      " -1.44040520e-01 -9.38055500e-02 -1.79444610e-01  9.07967030e-01\n",
      "  4.58149900e-02 -1.34548600e-02  1.40400250e-01  1.44261750e+00\n",
      " -1.31226880e-01 -1.89852090e-01  1.66342680e-01  8.00445400e-01\n",
      "  1.35396710e-02  1.02705054e-01  7.08871900e-01 -6.77829440e-01\n",
      " -3.97279380e-01 -4.27062660e-02 -3.63357700e-01 -9.81528640e-01\n",
      " -3.70964800e-01  4.91225900e-02 -5.49853600e-01 -1.14582000e+00\n",
      " -2.86227940e-01  5.60082700e-02 -5.15618440e-01 -9.21306900e-01\n",
      " -2.81312640e-01 -1.16786600e-01 -5.82233000e-01 -3.71121970e-01\n",
      " -4.32709840e-01 -1.78235700e-01 -6.00247560e-01 -5.75833000e-03\n",
      " -4.22335620e-01 -2.04681520e-01 -3.89472200e-01  4.16664540e-01\n",
      " -3.06492060e-01 -2.52728280e-01 -1.94150570e-01  2.83551600e-01\n",
      " -3.38423100e-01 -2.82958420e-01 -8.62420200e-02  1.89743010e-01\n",
      " -1.69546140e-01 -1.90663890e-01  5.09641900e-02]\n",
      "[-0.10219722  0.18512763  0.10179709 -0.07553118 -0.10880988  0.06781448\n",
      " -0.32737717 -0.08927482 -0.01205022  0.0635512  -0.15262322 -0.05088612\n",
      " -0.05748211 -0.15839265  0.37654266  0.0345092   0.05474047  0.46622533\n",
      "  0.17406242  0.48967037  0.509727    0.37098047  0.22448798  0.00727568\n",
      "  0.01693994  0.10929501  0.15928744  0.02656173 -0.05608521  0.11430628\n",
      "  0.02703819  0.09542558  0.1705556   0.25050074  0.15462156  0.2685062\n",
      "  0.16598816  0.28543785  0.17145889 -0.03300731  0.00968141  0.10557032\n",
      "  0.23345196 -0.01775077  0.09950871  0.07927205  0.4936233  -0.04409541\n",
      " -0.07116843  0.19947138  0.94791085  0.31828958  0.43913272  1.1081792\n",
      " -0.2009249   0.7159194   0.54537386  0.5567155   0.09572477  0.28720453\n",
      "  0.28406045  0.33944046  0.0628119   0.2240196   0.23637886  0.26335946\n",
      " -0.12054137  0.15708585  0.20076402  0.11293978 -0.08014555  0.11645026\n",
      "  0.08549017 -0.10303646  0.29419774  0.02986002  0.03002918  0.03921254\n",
      "  0.8052754   0.08730101  0.05854147  0.21295713  1.326814    0.14892308\n",
      " -0.02472826  0.36695653  1.3235325   0.2555578   0.3268352   0.8527412\n",
      " -0.31500894  0.6384639   0.60421777  0.5027603  -0.3476001   0.33503413\n",
      "  0.35142615  0.38751826 -0.2139588   0.18039307  0.26791406  0.2759125\n",
      " -0.36788255  0.07758477  0.08785982 -0.06891378 -0.04962096 -0.11422623\n",
      " -0.09322155 -0.27112415  0.14647067 -0.14404052 -0.09380555 -0.17944461\n",
      "  0.90796703  0.04581499 -0.01345486  0.14040025  1.4426175  -0.13122688\n",
      " -0.18985209  0.16634268  0.8004454   0.01353967  0.10270505  0.7088719\n",
      " -0.67782944 -0.39727938 -0.04270627 -0.3633577  -0.98152864 -0.3709648\n",
      "  0.04912259 -0.5498536  -1.14582    -0.28622794  0.05600827 -0.51561844\n",
      " -0.9213069  -0.28131264 -0.1167866  -0.582233   -0.37112197 -0.43270984\n",
      " -0.1782357  -0.60024756 -0.00575833 -0.42233562 -0.20468152 -0.3894722\n",
      "  0.41666454 -0.30649206 -0.25272828 -0.19415057  0.2835516  -0.3384231\n",
      " -0.28295842 -0.08624202  0.18974301 -0.16954614 -0.19066389  0.05096419]\n",
      "[ 0.21295713  1.326814    0.14892308 -0.02472826  0.36695653  1.3235325\n",
      "  0.2555578   0.3268352   0.8527412  -0.31500894  0.6384639   0.60421777\n",
      "  0.5027603  -0.3476001   0.33503413  0.35142615  0.38751826 -0.2139588\n",
      "  0.18039307  0.26791406  0.2759125  -0.36788255  0.07758477  0.08785982\n",
      " -0.06891378 -0.04962096 -0.11422623 -0.09322155 -0.27112415  0.14647067\n",
      " -0.14404052 -0.09380555 -0.17944461  0.90796703  0.04581499 -0.01345486\n",
      "  0.14040025  1.4426175  -0.13122688 -0.18985209  0.16634268  0.8004454\n",
      "  0.01353967  0.10270505  0.7088719  -0.67782944 -0.39727938 -0.04270627\n",
      " -0.3633577  -0.98152864 -0.3709648   0.04912259 -0.5498536  -1.14582\n",
      " -0.28622794  0.05600827 -0.51561844 -0.9213069  -0.28131264 -0.1167866\n",
      " -0.582233   -0.37112197 -0.43270984 -0.1782357  -0.60024756 -0.00575833\n",
      " -0.42233562 -0.20468152 -0.3894722   0.41666454 -0.30649206 -0.25272828\n",
      " -0.19415057  0.2835516  -0.3384231  -0.28295842 -0.08624202  0.18974301\n",
      " -0.16954614 -0.19066389  0.05096419]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "[[2.2493108e+03 1.4951920e+03 1.3288309e+03 1.8442101e+03 2.0124934e+04\n",
      "  1.3302759e+04 1.1504303e+04 1.3058663e+04 3.7949051e+04 2.4192615e+04\n",
      "  1.9092648e+04 2.4520775e+04 4.1693383e+04 2.6648846e+04 1.9842307e+04\n",
      "  2.5344885e+04 2.9915912e+04 1.7962824e+04 1.1164329e+04 1.6691500e+04\n",
      "  9.6580547e+03 5.0244790e+03 1.5640781e+03 4.6463911e+03 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 4.3595410e+03 3.0888894e+03 6.8479761e+03 7.7523926e+03\n",
      "  4.2587438e+04 4.4559426e+04 7.1637734e+04 5.0149738e+04 6.1308055e+04\n",
      "  6.5571359e+04 9.0126664e+04 5.7700629e+04 6.4228711e+04 7.0618742e+04\n",
      "  9.2417883e+04 5.3778352e+04 6.4648344e+04 6.9864555e+04 8.3241414e+04\n",
      "  5.4551957e+04 4.5820738e+04 4.6488867e+04 3.6153844e+04 2.8564721e+04\n",
      "  7.0658237e+03 3.3298386e+03 2.7536261e+02 3.3179065e+03 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.0854233e+03\n",
      "  6.5446611e+03 0.0000000e+00 3.3569832e+04 8.0838508e+04 3.3237531e+04\n",
      "  0.0000000e+00 5.6486711e+04 9.6756289e+04 2.8678375e+04 0.0000000e+00\n",
      "  6.0167203e+04 9.9517047e+04 3.1905936e+04 0.0000000e+00 7.2963914e+04\n",
      "  1.0286060e+05 3.5752820e+04 2.5497262e+04 6.5047762e+04 7.5349555e+04\n",
      "  2.2566166e+04 1.2282388e+04 1.1766404e+04 5.9567954e+03 6.2921499e+03\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.7684493e+03 7.0003369e+02 0.0000000e+00 1.5453867e+03 2.4307773e+04\n",
      "  1.5842749e+03 0.0000000e+00 1.5737923e+04 3.6399879e+04 1.4412579e+04\n",
      "  1.9390662e+03 5.0484008e+04 8.6596492e+04 5.4190371e+04 0.0000000e+00\n",
      "  7.1062938e+04 1.0208515e+05 4.9572543e+04 2.3717908e+04 7.2680672e+04\n",
      "  8.7497906e+04 3.1400434e+04 2.8558176e+04 2.8693600e+04 1.6453881e+04\n",
      "  1.2237666e+04 3.6930188e+03 1.7128374e+03 1.8688536e+02 1.7087168e+03\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 4.9212363e+03 2.3526879e+04\n",
      "  1.8256229e+04 0.0000000e+00 5.5895203e+04 9.7295000e+04 4.2445605e+04\n",
      "  0.0000000e+00 7.1182578e+04 1.0479086e+05 4.0969086e+04 2.9622164e+04\n",
      "  7.4441070e+04 1.0071765e+05 3.8983516e+04 4.8711734e+04 7.1808141e+04\n",
      "  7.7348555e+04 3.8644094e+04 2.9801344e+04 2.2864426e+04 1.1367292e+04\n",
      "  1.4833191e+04 1.4228899e+02 6.5115875e+01 2.7448163e+00 6.6219742e+01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.1868147e+04 4.4738569e+03 0.0000000e+00 1.2783606e+04 5.5401555e+04\n",
      "  5.1361128e+03 0.0000000e+00 2.6298998e+04 7.1013656e+04 0.0000000e+00\n",
      "  0.0000000e+00 5.5747742e+04 9.7816898e+04 2.7317145e+04 1.6589922e+04\n",
      "  7.0681969e+04 1.0051419e+05 3.6207824e+04 2.4021104e+04 4.2653391e+04\n",
      "  3.3008254e+04 1.1689024e+04 2.8491519e+02 2.6814743e+02 1.3210730e+02\n",
      "  1.4650520e+02 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  4.8319220e+02 3.1073233e+02 3.8184644e+02 5.1267365e+02 2.7841549e+04\n",
      "  2.0046920e+04 2.3164064e+04 2.5752338e+04 7.0959211e+04 4.8894859e+04\n",
      "  4.1966805e+04 5.0238602e+04 7.1264867e+04 4.9077906e+04 4.6180277e+04\n",
      "  5.4265984e+04 4.5918391e+04 5.1869246e+04 8.2718969e+04 6.0508414e+04\n",
      "  0.0000000e+00 6.5954398e+04 9.7030320e+04 4.0629098e+04 0.0000000e+00\n",
      "  4.1386254e+04 3.4333004e+04 0.0000000e+00 0.0000000e+00 2.6897745e+02\n",
      "  1.5318382e+02 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 7.8822021e+01 5.7574402e+02 6.2482483e+02\n",
      "  2.2001680e+03 1.7631568e+04 4.0570852e+04 3.3639816e+04 3.1173320e+04\n",
      "  6.5359980e+04 1.0054974e+05 5.6635996e+04 3.4440348e+04 6.8291898e+04\n",
      "  1.0418332e+05 5.8510012e+04 6.7532676e+03 6.4356047e+04 9.9046477e+04\n",
      "  5.5400488e+04 0.0000000e+00 4.9598477e+04 7.7199938e+04 1.5596432e+04\n",
      "  0.0000000e+00 1.6320373e+04 1.5420635e+04 0.0000000e+00 0.0000000e+00\n",
      "  5.4929241e+01 3.7650242e+01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3272482e+02\n",
      "  1.1580230e+01 0.0000000e+00 0.0000000e+00 2.2239797e+04 6.9124282e+03\n",
      "  0.0000000e+00 2.8022195e+04 7.5978203e+04 8.9455244e+03 0.0000000e+00\n",
      "  4.2192273e+04 8.6899383e+04 1.2914989e+04 0.0000000e+00 3.9141996e+04\n",
      "  7.7911328e+04 5.5289434e+03 0.0000000e+00 1.9932033e+04 2.4929969e+04\n",
      "  0.0000000e+00 0.0000000e+00 1.0774070e+03 7.4551672e+02 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "Output shape of the Dense layer: (1, 324)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rishit Thakkar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "weights_and_biases = np.loadtxt(\"model_weights.txt\")\n",
    "\n",
    "weights_shape = (3, 3, 1, 4)  # Assuming kernel size of (3, 3) and 4 filters\n",
    "weights2_shape = (3, 3, 4, 4)\n",
    "weights3_shape = (324, 10)\n",
    "\n",
    "weights = weights_and_biases[0:36].reshape(weights_shape)  # weights\n",
    "biases = weights_and_biases[36:40]  # biases\n",
    "\n",
    "weights2 = weights_and_biases[40:184].reshape(weights2_shape)\n",
    "biases2 = weights_and_biases[184:188]\n",
    "\n",
    "weights3 = weights_and_biases[188:3428].reshape(weights3_shape)\n",
    "biases3 = weights_and_biases[3428:3438]\n",
    "\n",
    "print(weights3)\n",
    "print(weights3.shape)\n",
    "print(weights3[0*81:,2])\n",
    "print(weights3[1*81:,2])\n",
    "print(weights3[2*81:,2])\n",
    "print(weights3[3*81:,2])\n",
    "\n",
    "#Model Below\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape=(42, 42, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(10, activation='relu'))\n",
    "\n",
    "model.layers[0].set_weights([weights, biases])\n",
    "model.layers[2].set_weights([weights2, biases2])\n",
    "#model.layers[5].set_weights([weights3, biases3])\n",
    "\n",
    "\n",
    "img_path = 'demo7.png'  \n",
    "img = image.load_img(img_path, target_size=(42, 42), color_mode='grayscale')  \n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "# img_array /= 255.  \n",
    "img_flat = img_array.flatten()\n",
    "img_array = np.array(img_flat)\n",
    "\n",
    "\n",
    "img_array = img_flat.reshape((1, 42, 42, 1))  # Reshape to (batch_size, height, width, channels)\n",
    "\n",
    "max2_output = model.predict(img_array)\n",
    "\n",
    "print(max2_output)\n",
    "# Save the convolutional layer output\n",
    "print(\"Output shape of the Dense layer:\", max2_output.shape)\n",
    "\n",
    "# Save the dense layer output\n",
    "#with open('Python_prog_out_Dense.txt', 'w') as file:\n",
    "#    for i in range(conv1_output.shape[1]):\n",
    "#        file.write(\"Neuron %d: %0.2f\\n\" % (i + 1, max2_output[0, i]))\n",
    "\n",
    "#print(\"Dense layer output saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fb4151c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0628828  -0.56143224 -0.05777652 -0.64277047 -0.27630126 -0.42569417\n",
      " -0.5058803  -0.35963646 -0.1291364  -0.18747672 -0.3822866  -0.21757637\n",
      " -0.02284618 -0.05292128 -0.19709247  0.0532147   0.11098424  0.24711229\n",
      " -0.14949729  0.29329622  0.10942538  0.2631237  -0.16586132  0.21083163\n",
      "  0.05651291  0.20739934 -0.14853683  0.11621948  0.03766488 -0.08272779\n",
      " -0.26614848 -0.10072731  0.01199793 -0.5397823  -0.5534407  -0.4611396\n",
      " -0.1588125  -0.94191325 -0.56085294 -0.6822576  -0.22096969 -0.34391403\n",
      " -0.05221902 -0.3895572  -0.28058553 -0.20277134 -0.10204247 -0.09077868\n",
      " -0.11321877 -0.04481785 -0.04376646 -0.06871933  0.05159071  0.08951378\n",
      "  0.03366006  0.11962752  0.16428761  0.20122069  0.15618005  0.15385604\n",
      "  0.19331625  0.12807706  0.18847096  0.0253465   0.06075673  0.07465037\n",
      "  0.19048187  0.02102919 -0.12028682  0.00505031 -0.25680864 -0.04713763\n",
      " -0.10192462 -0.54220045 -0.45827302 -0.52211756 -0.28032726 -0.1621164\n",
      " -0.07669959 -0.0978513  -0.14429691 -0.06501123 -0.03799545 -0.06434718\n",
      "  0.02613667  0.03140962  0.00333848  0.11052515  0.01027973  0.05598521\n",
      "  0.1574446   0.03246965 -0.09124562  0.19281973  0.16985793 -0.00874198\n",
      "  0.12858535  0.23754655  0.18872735  0.10717533  0.29578823  0.19987835\n",
      "  0.07835947  0.11153436  0.11946584  0.2815846   0.1879369   0.0540312\n",
      "  0.13045208 -0.615956   -0.31596637 -0.00534041  0.06655673  0.02306986\n",
      "  0.01010728  0.08411594  0.07084475  0.06424688 -0.03589844  0.21915153\n",
      " -0.31489146  0.1719721   0.08247464  0.059049   -1.514383   -0.24540211\n",
      " -0.11497485 -0.3262096  -2.188191   -0.43717015 -0.19591062 -0.67451507\n",
      " -0.73720056  0.07616738  0.14074159 -0.14208256  0.00787939  0.27669632\n",
      "  0.20606577  0.25929862  0.30211762  0.67413324  0.55753106  0.59066856\n",
      " -0.07065795 -0.30571297 -0.32067925  0.0732089  -0.11302944  0.13305123\n",
      "  0.06804305  0.17562616 -0.20803584  0.28854892  0.19987021  0.33434013\n",
      " -0.9551801   0.10626091  0.06540281  0.0483953  -2.1141129  -0.67750263\n",
      " -0.64715225 -1.4898094  -0.92500424 -0.90800786 -0.7583858  -0.47732747\n",
      " -0.70326823  0.02428607  0.1611498   0.2096562  -0.6079428   0.26866916\n",
      "  0.25784877  0.2040447  -0.4344521   0.63441646  0.49704647  0.40963417\n",
      " -0.59631294 -0.14181237 -0.08423562  0.0956463  -0.73819757  0.11204874\n",
      "  0.14271292  0.19705124 -0.7627638   0.37298575  0.29416725  0.28944623\n",
      " -0.46054658  0.1532622   0.04962102 -0.1294009   0.06526487 -0.79753506\n",
      " -1.0434515  -0.390272    0.05218927 -0.3107656  -0.24247028  0.00839862\n",
      " -0.26399162  0.16008659  0.19999975  0.36876288 -0.93414974  0.2553983\n",
      "  0.13867529  0.18210714 -0.7803716   0.3053215   0.50935477  0.25862482\n",
      " -0.6505005  -0.2134988   0.07725285  0.08091378 -1.1452392   0.26117408\n",
      "  0.15211283  0.16528632 -0.26143408  0.31149304  0.26557046  0.17116141\n",
      "  0.29758215  0.25724652  0.1612399   0.05987052  0.41428065 -0.00340675\n",
      " -0.11577219  0.03718248  0.19063735 -0.03394246  0.02566948  0.19841237\n",
      " -0.14215916  0.08557122  0.08187269  0.23798749 -0.6632405  -0.05365345\n",
      " -0.00330858  0.21069491 -0.6889576   0.20456168  0.09849864 -0.1185374\n",
      " -0.80617744 -0.04114443 -0.08300875  0.20461647 -0.99832207  0.30818504\n",
      "  0.17045204  0.14300138 -0.16807577  0.164416    0.16560122  0.17740433\n",
      "  0.25033933  0.31059477  0.14664619  0.12548433  0.5508307   0.1721905\n",
      "  0.0746824   0.08278626  0.42570245 -0.03417035 -0.04032369  0.13209842\n",
      "  0.0428728  -0.21406992 -0.08088593  0.10507305 -0.8031305   0.03038143\n",
      "  0.12656882  0.06251331 -0.35241133 -0.05947521 -0.02175829 -0.24035381\n",
      " -0.278819   -0.80139554 -0.6321179  -0.7552288  -1.1643255  -0.27386177\n",
      " -0.00391107 -0.80142933 -1.3118421  -0.17264876  0.056351   -0.71485037\n",
      " -0.81444514  0.10044821  0.19709332 -0.34825355 -0.07837331 -0.02069198\n",
      "  0.14407954 -0.15955585  0.06230567 -0.23012453 -0.11441158 -0.22529112\n",
      " -0.5456118  -0.5841881  -0.352891   -0.7437295  -0.41020682 -0.8797704\n",
      " -0.5625466  -0.79341656 -0.301025   -0.6929802  -0.4157763  -0.6351339 ]\n",
      "(324, 10)\n"
     ]
    }
   ],
   "source": [
    "print(weights3[:,0])\n",
    "print(weights3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c06e2482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.2493108e+03 1.4951920e+03 1.3288309e+03 1.8442101e+03 2.0124934e+04\n",
      "  1.3302759e+04 1.1504303e+04 1.3058663e+04 3.7949051e+04 2.4192615e+04\n",
      "  1.9092648e+04 2.4520775e+04 4.1693383e+04 2.6648846e+04 1.9842307e+04\n",
      "  2.5344885e+04 2.9915912e+04 1.7962824e+04 1.1164329e+04 1.6691500e+04\n",
      "  9.6580547e+03 5.0244790e+03 1.5640781e+03 4.6463911e+03 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 4.3595410e+03 3.0888894e+03 6.8479761e+03 7.7523926e+03\n",
      "  4.2587438e+04 4.4559426e+04 7.1637734e+04 5.0149738e+04 6.1308055e+04\n",
      "  6.5571359e+04 9.0126664e+04 5.7700629e+04 6.4228711e+04 7.0618742e+04\n",
      "  9.2417883e+04 5.3778352e+04 6.4648344e+04 6.9864555e+04 8.3241414e+04\n",
      "  5.4551957e+04 4.5820738e+04 4.6488867e+04 3.6153844e+04 2.8564721e+04\n",
      "  7.0658237e+03 3.3298386e+03 2.7536261e+02 3.3179065e+03 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.0854233e+03\n",
      "  6.5446611e+03 0.0000000e+00 3.3569832e+04 8.0838508e+04 3.3237531e+04\n",
      "  0.0000000e+00 5.6486711e+04 9.6756289e+04 2.8678375e+04 0.0000000e+00\n",
      "  6.0167203e+04 9.9517047e+04 3.1905936e+04 0.0000000e+00 7.2963914e+04\n",
      "  1.0286060e+05 3.5752820e+04 2.5497262e+04 6.5047762e+04 7.5349555e+04\n",
      "  2.2566166e+04 1.2282388e+04 1.1766404e+04 5.9567954e+03 6.2921499e+03\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.7684493e+03 7.0003369e+02 0.0000000e+00 1.5453867e+03 2.4307773e+04\n",
      "  1.5842749e+03 0.0000000e+00 1.5737923e+04 3.6399879e+04 1.4412579e+04\n",
      "  1.9390662e+03 5.0484008e+04 8.6596492e+04 5.4190371e+04 0.0000000e+00\n",
      "  7.1062938e+04 1.0208515e+05 4.9572543e+04 2.3717908e+04 7.2680672e+04\n",
      "  8.7497906e+04 3.1400434e+04 2.8558176e+04 2.8693600e+04 1.6453881e+04\n",
      "  1.2237666e+04 3.6930188e+03 1.7128374e+03 1.8688536e+02 1.7087168e+03\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 4.9212363e+03 2.3526879e+04\n",
      "  1.8256229e+04 0.0000000e+00 5.5895203e+04 9.7295000e+04 4.2445605e+04\n",
      "  0.0000000e+00 7.1182578e+04 1.0479086e+05 4.0969086e+04 2.9622164e+04\n",
      "  7.4441070e+04 1.0071765e+05 3.8983516e+04 4.8711734e+04 7.1808141e+04\n",
      "  7.7348555e+04 3.8644094e+04 2.9801344e+04 2.2864426e+04 1.1367292e+04\n",
      "  1.4833191e+04 1.4228899e+02 6.5115875e+01 2.7448163e+00 6.6219742e+01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.1868147e+04 4.4738569e+03 0.0000000e+00 1.2783606e+04 5.5401555e+04\n",
      "  5.1361128e+03 0.0000000e+00 2.6298998e+04 7.1013656e+04 0.0000000e+00\n",
      "  0.0000000e+00 5.5747742e+04 9.7816898e+04 2.7317145e+04 1.6589922e+04\n",
      "  7.0681969e+04 1.0051419e+05 3.6207824e+04 2.4021104e+04 4.2653391e+04\n",
      "  3.3008254e+04 1.1689024e+04 2.8491519e+02 2.6814743e+02 1.3210730e+02\n",
      "  1.4650520e+02 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  4.8319220e+02 3.1073233e+02 3.8184644e+02 5.1267365e+02 2.7841549e+04\n",
      "  2.0046920e+04 2.3164064e+04 2.5752338e+04 7.0959211e+04 4.8894859e+04\n",
      "  4.1966805e+04 5.0238602e+04 7.1264867e+04 4.9077906e+04 4.6180277e+04\n",
      "  5.4265984e+04 4.5918391e+04 5.1869246e+04 8.2718969e+04 6.0508414e+04\n",
      "  0.0000000e+00 6.5954398e+04 9.7030320e+04 4.0629098e+04 0.0000000e+00\n",
      "  4.1386254e+04 3.4333004e+04 0.0000000e+00 0.0000000e+00 2.6897745e+02\n",
      "  1.5318382e+02 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 7.8822021e+01 5.7574402e+02 6.2482483e+02\n",
      "  2.2001680e+03 1.7631568e+04 4.0570852e+04 3.3639816e+04 3.1173320e+04\n",
      "  6.5359980e+04 1.0054974e+05 5.6635996e+04 3.4440348e+04 6.8291898e+04\n",
      "  1.0418332e+05 5.8510012e+04 6.7532676e+03 6.4356047e+04 9.9046477e+04\n",
      "  5.5400488e+04 0.0000000e+00 4.9598477e+04 7.7199938e+04 1.5596432e+04\n",
      "  0.0000000e+00 1.6320373e+04 1.5420635e+04 0.0000000e+00 0.0000000e+00\n",
      "  5.4929241e+01 3.7650242e+01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3272482e+02\n",
      "  1.1580230e+01 0.0000000e+00 0.0000000e+00 2.2239797e+04 6.9124282e+03\n",
      "  0.0000000e+00 2.8022195e+04 7.5978203e+04 8.9455244e+03 0.0000000e+00\n",
      "  4.2192273e+04 8.6899383e+04 1.2914989e+04 0.0000000e+00 3.9141996e+04\n",
      "  7.7911328e+04 5.5289434e+03 0.0000000e+00 1.9932033e+04 2.4929969e+04\n",
      "  0.0000000e+00 0.0000000e+00 1.0774070e+03 7.4551672e+02 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "(1, 324)\n"
     ]
    }
   ],
   "source": [
    "print(max2_output)\n",
    "print(max2_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce4addb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86c57dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -500694.41436946 -1309289.3143765   -201958.50022189   547047.20066867\n",
      "   -839979.49999342     7207.10891517  -738034.48166799  -492147.15098327\n",
      "     23648.22340149  -653783.05755579]]\n"
     ]
    }
   ],
   "source": [
    "print(np.matmul(max2_output, weights3) + biases3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
