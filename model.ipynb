{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "978ab77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 16:59:25.792958: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1104e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 17:12:30.101773: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 48s 100ms/step - loss: 0.9458 - accuracy: 0.6989 - val_loss: 0.3480 - val_accuracy: 0.8979\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.3024 - accuracy: 0.9082 - val_loss: 0.2520 - val_accuracy: 0.9232\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.2349 - accuracy: 0.9292 - val_loss: 0.2089 - val_accuracy: 0.9389\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1889 - accuracy: 0.9438 - val_loss: 0.1587 - val_accuracy: 0.9525\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.1588 - accuracy: 0.9523 - val_loss: 0.1347 - val_accuracy: 0.9590\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1352 - accuracy: 0.9598 - val_loss: 0.1257 - val_accuracy: 0.9617\n",
      "Epoch 7/10\n",
      "182/469 [==========>...................] - ETA: 26s - loss: 0.1190 - accuracy: 0.9650"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.utils import to_categorical\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Resize images to 42x42\n",
    "x_train_resized = np.zeros((x_train.shape[0], 42, 42))\n",
    "for i in range(x_train.shape[0]):\n",
    "    x_train_resized[i] = resize(x_train[i], (42, 42))\n",
    "\n",
    "x_test_resized = np.zeros((x_test.shape[0], 42, 42))\n",
    "for i in range(x_test.shape[0]):\n",
    "    x_test_resized[i] = resize(x_test[i], (42, 42))\n",
    "\n",
    "# Reshape to add channel dimension (required for Keras)\n",
    "x_train_resized = x_train_resized.reshape(-1, 42, 42, 1)\n",
    "x_test_resized = x_test_resized.reshape(-1, 42, 42, 1)\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "x_train_resized = x_train_resized.astype('float32') / 255.0\n",
    "x_test_resized = x_test_resized.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Create CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(42, 42, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_resized, y_train, batch_size=128, epochs=10, validation_data=(x_test_resized, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test_resized, y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8759a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e1de1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24b7ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_resized = np.zeros((x_train.shape[0], 42, 42))\n",
    "x_test_resized = np.zeros((x_test.shape[0], 42, 42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df7971dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 42, 42, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train_resized, -1)\n",
    "x_test = np.expand_dims(x_test_resized, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c72ba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e45b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    img = Image.fromarray(x_train[i])\n",
    "    img_resized = img.resize((42, 42), resample=Image.LANCZOS)\n",
    "    x_train_resized[i] = np.array(img_resized)\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    img = Image.fromarray(x_test[i])\n",
    "    img_resized = img.resize((42, 42), resample=Image.LANCZOS)\n",
    "    x_test_resized[i] = np.array(img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1efbc484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_resized shape: [[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n",
      "x_test_resized shape: [[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n"
     ]
    }
   ],
   "source": [
    "# x_train_resized = np.expand_dims(x_train_resized, axis=-1)\n",
    "# x_test_resized = np.expand_dims(x_test_resized, axis=-1)\n",
    "\n",
    "# print(\"x_train_resized shape:\", x_train_resized.shape)\n",
    "# print(\"x_test_resized shape:\", x_test_resized.shape)\n",
    "\n",
    "print(\"x_train_resized shape:\", x_train)\n",
    "print(\"x_test_resized shape:\", x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91b7a299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(9):\n",
    " # define subplot\n",
    " plt.subplot(330 + 1 + i)\n",
    " # plot raw pixel data\n",
    " plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9872ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from qkeras import QConv2D, QActivation, QDense\n",
    "from tensorflow.keras.layers import Input, Flatten, Activation, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f2e0f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 16:51:28.192368: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/esp2024/rht2122/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 42, 42, 1)]       0         \n",
      "                                                                 \n",
      " q_conv2d (QConv2D)          (None, 40, 40, 4)         40        \n",
      "                                                                 \n",
      " q_activation (QActivation)  (None, 40, 40, 4)         0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 20, 20, 4)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " q_conv2d_1 (QConv2D)        (None, 18, 18, 4)         148       \n",
      "                                                                 \n",
      " q_activation_1 (QActivation  (None, 18, 18, 4)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 9, 9, 4)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 324)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 324)               0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 10)                3250      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,438\n",
      "Trainable params: 3,438\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the input shape\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "x = QConv2D(4, (3, 3), kernel_quantizer=\"quantized_bits(2,6)\")(inputs)\n",
    "x = QActivation(\"quantized_relu(2,6)\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = QConv2D(4, (3, 3), kernel_quantizer=\"quantized_bits(2,6)\")(x)\n",
    "x = QActivation(\"quantized_relu(2,6)\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = QDense(num_classes, activation=\"softmax\", kernel_quantizer=\"quantized_bits(2,6)\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a12dcc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 29s 16ms/step - loss: 2.3012 - accuracy: 0.1132 - val_loss: 2.3021 - val_accuracy: 0.1050\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 27s 16ms/step - loss: 2.3013 - accuracy: 0.1132 - val_loss: 2.3019 - val_accuracy: 0.1050\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 26s 15ms/step - loss: 2.3013 - accuracy: 0.1132 - val_loss: 2.3020 - val_accuracy: 0.1050\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 26s 16ms/step - loss: 2.3013 - accuracy: 0.1132 - val_loss: 2.3020 - val_accuracy: 0.1050\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 26s 16ms/step - loss: 2.3013 - accuracy: 0.1132 - val_loss: 2.3020 - val_accuracy: 0.1050\n",
      "Epoch 6/10\n",
      " 208/1688 [==>...........................] - ETA: 22s - loss: 2.3005 - accuracy: 0.1112"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[1;32m     12\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train, x_test = x_train_resized, x_test_resized\n",
    "y_train, y_test = y_train, y_test\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=10, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468bad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Define a callback to save the weights during training\n",
    "checkpoint_callback = ModelCheckpoint(filepath='model_weights.h5',  # Path to save the weights\n",
    "                                      save_weights_only=True,       # Save only the weights\n",
    "                                      monitor='val_accuracy',       # Monitor validation accuracy\n",
    "                                      mode='max',                   # Save mode (maximize validation accuracy)\n",
    "                                      save_best_only=True)         # Save only the best weights\n",
    "\n",
    "# Train the model with the callback to save weights\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_split=0.1,\n",
    "          callbacks=[checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5c7e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
